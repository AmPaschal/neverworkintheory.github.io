---
layout: post
author: Greg Wilson
title: "A Multi-Site Joint Replication of a Design Patterns Experiment Using Moderator Variables to Generalize Across Contexts"
date: 2016-09-09
categories: ["Design Patterns"]
---
<p id="Krein2016" class="bib">
  <a class="bibkey" href="/bib/#Krein2016">Krein2016</a>
  Jonathan L. Krein, Lutz Prechelt, Natalia Juristo, Aziz Nanthaamornphong, Jeffrey C. Carver, Sira Vegas, Charles D. Knutson, Kevin D. Seppi, and Dennis L. Eggett:
  "<a href="https://doi.org/10.1109/tse.2015.2488625">A Multi-Site Joint Replication of a Design Patterns Experiment Using Moderator Variables to Generalize across Contexts</a>".
  <em>IEEE Transactions on Software Engineering</em>, 42(4), 2016,
  <a class="doi" href="https://doi.org/10.1109/tse.2015.2488625">10.1109/tse.2015.2488625</a>.
</p>
<blockquote class="abstract">
  <p>
  <strong>Context.</strong>  Several empirical studies have explored
  the benefits of software design patterns, but their collective
  results are highly inconsistent. Resolving the inconsistencies
  requires investigating moderators—i.e., variables that cause an
  effect to differ across contexts.
  </p>
  <p>
  <strong>Objectives.</strong>  Replicate a design patterns
  experiment at multiple sites and identify sufficient moderators to
  generalize the results across prior studies.
  </p>
  <p>
  <strong>Methods.</strong>  We perform a close replication of an
  experiment investigating the impact (in terms of time and quality)
  of design patterns (Decorator and Abstract Factory) on software
  maintenance. The experiment was replicated once previously, with
  divergent results. We execute our replication at four
  universities—spanning two continents and three countries—using a
  new method for performing distributed replications based on
  closely coordinated, small-scale instances ("joint
  replication"). We perform two analyses: 1) a post-hoc analysis of
  moderators, based on frequentist and Bayesian statistics; 2) an a
  priori analysis of the original hypotheses, based on frequentist
  statistics.
  </p>
  <p>
  <strong>Results.</strong>  The main effect differs across the
  previous instances of the experiment and across the sites in our
  distributed replication. Our analysis of moderators (including
  developer experience and pattern knowledge) resolves the
  differences sufficiently to allow for cross-context (and
  cross-study) conclusions. The final conclusions represent 126
  participants from five universities and 12 software companies,
  spanning two continents and at least four countries.
  </p>
  <p>
  <strong>Conclusions.</strong>  The Decorator pattern is found to
  be preferable to a simpler solution during maintenance, as long as
  the developer has at least some prior knowledge of the
  pattern. For Abstract Factory, the simpler solution is found to be
  mostly equivalent to the pattern solution. Abstract Factory is
  shown to require a higher level of knowledge and/or experience
  than Decorator for the pattern to be beneficial.
  </p>
</blockquote>
<div class="review">
<p>
  This paper's conclusions about the efficacy of two particular design
  patterns are less important than its demonstration that claims about
  software design can be tested rigorously through carefully-designed
  studies.  The experimental and statistical methods used would be
  immediately familiar to anyone working in public health, and the
  claims are carefully circumscribed.  The end result is less rousing
  than the rhetoric found in many popular books, but I believe that's
  a sign of our field's increasing maturity.
</p>
</div>
