---
layout: post
author: Hamza Alvi
title: "Deep Code Search"
date: 2021-11-30
categories: ["Code Search", "Deep Learning"]
---
<div class="review">
  <p>
    Kim is a developer, and during the implementation of a feature, he 
    remembers that he wrote a similar kind of functionality in another 
    project. So, he opened the project and started searching for the code. 
    It took some time, but the code was identified, which made his current 
    task easier. He wondered whether the time spent in the code search was 
    worth it because he might have taken the same amount of time to reimplement. 
    If Kim had a tool that helped him in code search then he might have saved some time.
    Not just Kim, every developer searches for code and reuses previously written 
    code by performing free-text queries. To help developers, Gu et. al. <cite>Gu2018</cite> 
    proposes a tool named DeepCS that takes natural language queries and searches for relevant code in a large-scale codebase.
  </p>
  <p>
    The DeepCS uses the CODEnn model to find the relevant code snippets from a codebase 
    given a natural language query. The CODEnn model consists of three modules:
    <ol>
      <li>A code embedding network (CoNN) that learns to embed code into vectors</li>
      <li>A description embedding network (DeNN) that learns to embed natural language descriptions into vectors</li>
      <li>A similarity module that measures the similarity between code and description vectors</li>
    </ol>
    CoNN and DeNN use recurrent neural networks to embed inputs into vectors. Whereas, 
    similarity module uses cosine similarity measure to find the closeness between 
    embedded inputs. Gu et. al. <cite>Gu2018</cite> used more than 18 million methods 
    extracted from Java projects on GitHub to train the CODEnn model and used Hinge 
    loss as a loss function. Hinge loss ensures that the learned vectors for description 
    are close to the vector of corresponding code and far from vectors other code.
  </p>
  <p>
    The DeepCS tool works in three steps. In the first step, DeepCS takes a codebase as 
    input and computes code vectors of methods present in the codebase using CoNN module. 
    After this, DeepCS takes a user query and computes the embedding vector using the DeNN 
    module. Finally, DeepCS finds cosine similarity between query and code vectors obtained 
    in previous steps and returns the ten methods with the highest similarity. To 
    evaluate the performance of DeepCS, Gu collected 9,950 projects having at least 20 stars 
    from GitHub that contained more than 16 million methods. As a query, the authors used 
    the top 50 voted Java questions from Stack Overflow. The DeepCS had relevant code snippets 
    present in the top 10 results for 86% of queries compared to 66% for the previous 
    state-of-the-art. The DeepCS also had 49% relevant code snippets in the top 10 results 
    compared to only 28% for previous tools.
  </p>
  <p>
    Now Kim does not need to search manually for code snippets. To 
    search for code, he will provide DeepCS with the codebase that 
    he wants to search for code. After this, he will write a query, 
    and DeepCS will return the code snippets relevant to the query written by Kim.
  </p>
</div>
<p id="Gu2018" class="bib"><cite>Gu2018</cite>
  Xiaodong Gu, Hongyu Zhang, and Sunghun Kim:
  "<a href="https://doi.org/10.1145/3180155.3180167">Deep Code Search</a>".
  <em>Proceedings of the 40th International Conference on Software Engineering (ICSE)</em>, 2018,
  <a class="doi" href="https://doi.org/10.1145/3180155.3180167">10.1145/3180155.3180167</a>.
</p>
<blockquote class="abstract">
<p>
To implement a program functionality, developers can reuse previously written code snippets by searching through a large-scale codebase. Over 
the years, many code search tools have been proposed to help developers. The existing approaches often treat source code as textual documents 
and utilize information retrieval models to retrieve relevant code snippets that match a given query. These approaches mainly rely on the 
textual similarity between source code and natural language query. They lack a deep understanding of the semantics of queries and source code.
</p>
<p>
In this paper, we propose a novel deep neural network named CODEnn (Code-Description Embedding Neural Network). Instead of matching text similarity, 
CODEnn jointly embeds code snippets and natural language descriptions into a high-dimensional vector space, in such a way that code snippet and its 
corresponding description have similar vectors. Using the unified vector representation, code snippets related to a natural language query can be 
retrieved according to their vectors. Semantically related words can also be recognized and irrelevant/noisy keywords in queries can be handled.
</p>
<p>
As a proof-of-concept application, we implement a code search tool named DeepCS using the proposed CODEnn model. We empirically evaluate 
DeepCS on a large scale codebase collected from GitHub. The experimental results show that our approach can effectively retrieve relevant 
code snippets and outperforms previous techniques.
</p>
</blockquote>